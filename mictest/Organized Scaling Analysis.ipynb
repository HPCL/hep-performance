{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Analysis\n",
    "\n",
    "Author: Brain Gravelle (gravelle@cs.uoregon.edu)\n",
    "\n",
    "\n",
    "All this is using the taucmdr python libraries from paratools\n",
    "http://taucommander.paratools.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "This section imports necessary libraies, the metrics.py and utilities.py files and sets up the window.\n",
    "\n",
    "\n",
    "<a id='top'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A couple of scripts to set the environent and import data from a .tau set of results\n",
    "from utilities import *\n",
    "from metrics import *\n",
    "# Plotting, notebook settings:\n",
    "%matplotlib inline  \n",
    "#plt.rcParams.update({'font.size': 16})\n",
    "import numbers\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.float_format', lambda x: '%.2e' % x)\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('max_colwidth', 70)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data\n",
    "\n",
    "TAU Commander uses TAU to run the application and measure it using runtime sampling techniques (similar to Intel VTune). Many customization options are available. For example, we may consider each function regardless of calling context, or we may decide to enable callpath profiling to see each context separately.\n",
    "\n",
    "From the talapas_scaling application the following experiments are available. These use Talapas (with 28 thread Broadwell processors) and the build-ce (realistic) option for mkFit. The first six experiments use the --num-thr option to set the thread count which is intended to perform threading within the events. the last two add the --num-ev-thr option to set the event threads, so that all threads are used to process events in parallel and each event is processed by a single thread. \n",
    "* manual_scaling_Large_talapas\t\t\n",
    "* manual_scaling_Large_talapas_fullnode\t\n",
    "* manual_scaling_TTbar70_talapas\t\t\n",
    "* manual_scaling_TTbar70_talapas_fullnode\n",
    "* manual_scaling_TTbar35_talapas\n",
    "* manual_scaling_TTbar35_talapas_fullnode\n",
    "* ev_thr_scaling_Large_talapas\n",
    "* ev_thr_scaling_Large_talapas_fullnode\n",
    "\n",
    "Additionally available in the cori_scaling application are the following. These were run on NERSC's Cori on the KNL with the default memory settings (quad - 1 NUMA domain, cache - MCDRAM as direct mapped cache). See http://www.nersc.gov/users/computational-systems/cori/running-jobs/advanced-running-jobs-options/ for more info on the KNL modes. Similar to the talapas scaling they use the build-ce option and threading within each event.\n",
    "* manual_scaling_TTbar35\n",
    "* manual_scaling_TTbar70\n",
    "* manual_scaling_Large\n",
    "* mixed_thr_scaling_Large - this is bad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Scaling Data - Cori TTbar70 is current\n",
    "Here we import the data. In this case we are using Cori data from the experiments with the threads working within each event using the TTbar70 file. Note that this box will take an hour or more to run; please go enjoy a coffee while you wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application = \"talapas_scaling\"\n",
    "# experiment  = \"manual_scaling_TTbar70_talapas\"\n",
    "# experiment  = \"manual_scaling_Large_talapas\"\n",
    "# experiment = \"ev_thr_scaling_Large_talapas\"\n",
    "\n",
    "application = \"cori_scaling\"\n",
    "# experiment  = \"manual_scaling_TTbar35\"\n",
    "experiment  = \"manual_scaling_TTbar70\"\n",
    "# experiment  = \"manual_scaling_Large\"\n",
    "# experiment  = \"mixed_thr_scaling_Large\"\n",
    "\n",
    "path = \".tau/\" + application + \"/\" + experiment + \"/\"\n",
    "# note that this function takes a long time to run, so only rerun if you must\n",
    "\n",
    "metric_data = get_pandas_scaling(path, callpaths=True)\n",
    "    \n",
    "if application == \"talapas_scaling\":\n",
    "    metric_data = remove_erroneous_threads(metric_data,  [1, 8, 16, 32, 48, 56])\n",
    "elif application == \"cori_scaling\":\n",
    "    print(metric_data.keys())\n",
    "    metric_data = remove_erroneous_threads(metric_data,  [1, 4, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A list of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_available_metrics(metric_data,True)\n",
    "\n",
    "for key in metric_data[metric_data.keys()[5]]:\n",
    "    if not key == 'METADATA':\n",
    "        print(key)\n",
    "print(metric_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding metrics\n",
    "\n",
    "metrics are available in metrics.py. At this time the following can be added:\n",
    "* add_IPC(metrics)          - Instructions per Cycle\n",
    "* add_CPI(metrics)          - Cycles per instruction\n",
    "* add_VIPC(metrics)         - vector instructions per cycle\n",
    "* add_VIPI(metrics)         - vector instructions per instruction (i.e. fraction of total)\n",
    "* add_L1_missrate(metrics)  - miss rate for L1 cache\n",
    "\n",
    "for scaling data please use the add_metric_to_scaling_data(data, metric_func) function to add a metric\n",
    "\n",
    "Here we add some predeefined metrics and print the top 10 functions with the best IPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_metric_to_scaling_data(metric_data, add_CPI)\n",
    "add_metric_to_scaling_data(metric_data, add_IPC)\n",
    "add_metric_to_scaling_data(metric_data, add_L1_missrate)\n",
    "add_metric_to_scaling_data(metric_data, add_L2_missrate)\n",
    "add_metric_to_scaling_data(metric_data, add_VIPI)\n",
    "if application == 'cori_scaling': llc = True\n",
    "else: llc = False\n",
    "add_metric_to_scaling_data(metric_data, add_L3_missrate, llc)\n",
    "print_available_metrics(metric_data, scaling=True)\n",
    "\n",
    "add_metric_to_scaling_data(metric_data, add_DERIVED_BRANCH_MR)\n",
    "add_metric_to_scaling_data(metric_data, add_DERIVED_RATIO_FETCH_STL_TOT_CYC)\n",
    "\n",
    "# To test\n",
    "# metric_data[1]['DERIVED_IPC'].sort_values(by='Inclusive',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Results\n",
    "\n",
    "In this section we demo some scaling results with several different metrics.\n",
    "\n",
    "We use the scaling plot function to plot the data vs thread count.\n",
    "scaling_plot(data, inclusive=True, plot=True, function=\"\\[SUMMARY\\] .TAU application$\", metric='PAPI_TOT_CYC', max=False)\n",
    "* data = the full dictionary of scaling data \n",
    "* inclusive = determines if the inclusive data or exclusive data will be used\n",
    "* plot = true makes a plot false does not\n",
    "* function = the string that will be searched for to plot. Default looks at the whole application\n",
    "* metric = the metric choosen from the above list\n",
    "* max = use the max value or average value across the threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.light_palette(\"yellow\", as_cmap=True)\n",
    "\n",
    "corr_data = copy.deepcopy(alldata)\n",
    "corr_data = corr_data[corr_data.index.get_level_values('region').str.contains('FindCandidatesClone')]\n",
    "# corr_data.head(10)\n",
    "correlations_pearson = alldata.corr('pearson').fillna(0)    # Other methods: 'kendall', 'spearman'\n",
    "correlations_pearson.style.format(\"{:.2%}\").background_gradient(cmap=cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
