{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Analysis\n",
    "\n",
    "Author: Brain Gravelle (gravelle@cs.uoregon.edu)\n",
    "\n",
    "\n",
    "All this is using the taucmdr python libraries from paratools\n",
    "http://taucommander.paratools.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "This section imports necessary libraies, the metrics.py and utilities.py files and sets up the window.\n",
    "\n",
    "\n",
    "<a id='top'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A couple of scripts to set the environent and import data from a .tau set of results\n",
    "from utilities import *\n",
    "from metrics import *\n",
    "# Plotting, notebook settings:\n",
    "%matplotlib inline  \n",
    "#plt.rcParams.update({'font.size': 16})\n",
    "import numbers\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.float_format', lambda x: '%.2e' % x)\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('max_colwidth', 70)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#tot_cyc'>tot cyc</a><br>\n",
    "<a href='#l1_mr'>l1_mr</a><br>\n",
    "<a href='#l2_mr'>l2_mr</a><br>\n",
    "<a href='#l3_mr'>l3_mr</a><br>\n",
    "<a href='#branch_mr'>branch_mr</a><br>\n",
    "<a href='#fetch_stall'>fetch_stall</a><br>\n",
    "<a href='#vipi'>vipi</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data\n",
    "\n",
    "TAU Commander uses TAU to run the application and measure it using runtime sampling techniques (similar to Intel VTune). Many customization options are available. For example, we may consider each function regardless of calling context, or we may decide to enable callpath profiling to see each context separately.\n",
    "\n",
    "From the talapas_scaling application the following experiments are available. These use Talapas (with 28 thread Broadwell processors) and the build-ce (realistic) option for mkFit. The first six experiments use the --num-thr option to set the thread count which is intended to perform threading within the events. the last two add the --num-ev-thr option to set the event threads, so that all threads are used to process events in parallel and each event is processed by a single thread. \n",
    "* manual_scaling_Large_talapas\t\t\n",
    "* manual_scaling_Large_talapas_fullnode\t\n",
    "* manual_scaling_TTbar70_talapas\t\t\n",
    "* manual_scaling_TTbar70_talapas_fullnode\n",
    "* manual_scaling_TTbar35_talapas\n",
    "* manual_scaling_TTbar35_talapas_fullnode\n",
    "* ev_thr_scaling_Large_talapas\n",
    "* ev_thr_scaling_Large_talapas_fullnode\n",
    "\n",
    "Additionally available in the cori_scaling application are the following. These were run on NERSC's Cori on the KNL with the default memory settings (quad - 1 NUMA domain, cache - MCDRAM as direct mapped cache). See http://www.nersc.gov/users/computational-systems/cori/running-jobs/advanced-running-jobs-options/ for more info on the KNL modes. Similar to the talapas scaling they use the build-ce option and threading within each event.\n",
    "* manual_scaling_TTbar35\n",
    "* manual_scaling_TTbar70\n",
    "* manual_scaling_Large\n",
    "* mixed_thr_scaling_Large - this is bad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Scaling Data - Cori TTbar70 is current\n",
    "Here we import the data. In this case we are using Cori data from the experiments with the threads working within each event using the TTbar35 file. Note that this box will take an hour or more to run; please go enjoy a coffee while you wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application = \"talapas_scaling\"\n",
    "# experiment  = \"manual_scaling_TTbar70_talapas\"\n",
    "# experiment  = \"manual_scaling_Large_talapas\"\n",
    "# experiment = \"ev_thr_scaling_Large_talapas\"\n",
    "\n",
    "application = \"cori_scaling\"\n",
    "# experiment  = \"manual_scaling_TTbar35\"\n",
    "experiment  = \"manual_scaling_TTbar70\"\n",
    "# experiment  = \"manual_scaling_Large\"\n",
    "# experiment  = \"mixed_thr_scaling_Large\"\n",
    "\n",
    "path = \".tau/\" + application + \"/\" + experiment + \"/\"\n",
    "# note that this function takes a long time to run, so only rerun if you must\n",
    "\n",
    "metric_data = get_pandas_scaling(path, callpaths=True)\n",
    "    \n",
    "if application == \"talapas_scaling\":\n",
    "    metric_data = remove_erroneous_threads(metric_data,  [1, 8, 16, 32, 48, 56])\n",
    "elif application == \"cori_scaling\":\n",
    "    print(metric_data.keys())\n",
    "    metric_data = remove_erroneous_threads(metric_data,  [1, 4, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_data[8]['PAPI_TOT_CYC'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A list of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_available_metrics(metric_data,True)\n",
    "\n",
    "for key in metric_data[metric_data.keys()[5]]:\n",
    "    if not key == 'METADATA':\n",
    "        print(key)\n",
    "print(metric_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_metadata(metric_data[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding metrics\n",
    "\n",
    "metrics are available in metrics.py. At this time the following can be added:\n",
    "* add_IPC(metrics)          - Instructions per Cycle\n",
    "* add_CPI(metrics)          - Cycles per instruction\n",
    "* add_VIPC(metrics)         - vector instructions per cycle\n",
    "* add_VIPI(metrics)         - vector instructions per instruction (i.e. fraction of total)\n",
    "* add_L1_missrate(metrics)  - miss rate for L1 cache\n",
    "\n",
    "for scaling data please use the add_metric_to_scaling_data(data, metric_func) function to add a metric\n",
    "\n",
    "Here we add some predeefined metrics and print the top 10 functions with the best IPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_metric_to_scaling_data(metric_data, add_CPI)\n",
    "add_metric_to_scaling_data(metric_data, add_IPC)\n",
    "add_metric_to_scaling_data(metric_data, add_L1_missrate)\n",
    "add_metric_to_scaling_data(metric_data, add_L2_missrate)\n",
    "add_metric_to_scaling_data(metric_data, add_VIPI)\n",
    "if application == 'cori_scaling': llc = True\n",
    "else: llc = False\n",
    "add_metric_to_scaling_data(metric_data, add_L3_missrate, llc)\n",
    "print_available_metrics(metric_data, scaling=True)\n",
    "\n",
    "# metric_data[1]['DERIVED_IPC'].sort_values(by='Inclusive',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_DERIVED_BRANCH_MR(metrics):\n",
    "    if (not metrics.has_key('PAPI_BR_MSP')):\n",
    "        print 'ERROR adding DERIVED_BRANCH_MR to metric dictionary'\n",
    "        return False\n",
    "    a0 = metrics['PAPI_BR_MSP'].copy()\n",
    "    a0.index = a0.index.droplevel()\n",
    "    u0 = a0.unstack()\n",
    "    if (not metrics.has_key('PAPI_BR_CN')):\n",
    "        print 'ERROR adding DERIVED_BRANCH_MR to metric dictionary'\n",
    "        return False\n",
    "    a1 = metrics['PAPI_BR_CN'].copy()\n",
    "    a1.index = a1.index.droplevel()\n",
    "    u1 = a1.unstack()\n",
    "    metrics['DERIVED_BRANCH_MR'] = a0 / a1\n",
    "\n",
    "    return True\n",
    "\n",
    "def add_DERIVED_RATIO_FETCH_STL_TOT_CYC(metrics):\n",
    "    if (not metrics.has_key('PAPI_NATIVE_FETCH_STALL')):\n",
    "        print 'ERROR adding DERIVED_BRANCH_MR to metric dictionary'\n",
    "        return False\n",
    "    a0 = metrics['PAPI_BR_MSP'].copy()\n",
    "    a0.index = a0.index.droplevel()\n",
    "    u0 = a0.unstack()\n",
    "    if (not metrics.has_key('PAPI_TOT_CYC')):\n",
    "        print 'ERROR adding DERIVED_BRANCH_MR to metric dictionary'\n",
    "        return False\n",
    "    a1 = metrics['PAPI_BR_CN'].copy()\n",
    "    a1.index = a1.index.droplevel()\n",
    "    u1 = a1.unstack()\n",
    "    metrics['DERIVED_RATIO_FETCH_STL_TOT_CYC'] = a0 / a1\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "add_metric_to_scaling_data(metric_data, add_DERIVED_BRANCH_MR)\n",
    "add_metric_to_scaling_data(metric_data, add_DERIVED_RATIO_FETCH_STL_TOT_CYC)\n",
    "\n",
    "\n",
    "# metric_data[1]['DERIVED_BRANCH_MR'].sort_values(by='Inclusive',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Results\n",
    "\n",
    "In this section we demo some scaling results with several different metrics.\n",
    "\n",
    "We use the scaling plot function to plot the data vs thread count.\n",
    "scaling_plot(data, inclusive=True, plot=True, function=\"\\[SUMMARY\\] .TAU application$\", metric='PAPI_TOT_CYC', max=False)\n",
    "* data = the full dictionary of scaling data \n",
    "* inclusive = determines if the inclusive data or exclusive data will be used\n",
    "* plot = true makes a plot false does not\n",
    "* function = the string that will be searched for to plot. Default looks at the whole application\n",
    "* metric = the metric choosen from the above list\n",
    "* max = use the max value or average value across the threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling with total cycles vs the thread count\n",
    "Here we plot the cycle count for each thread count as a proxy for execution time. We use the max cycle count rather than the average as this number will limit the time of execution.\n",
    "\n",
    "<a id='tot_cyc'></a>\n",
    "\n",
    "<a href='#top'>top</a><br>\n",
    "<a href='#tot_cyc'>tot cyc</a><br>\n",
    "<a href='#l1_mr'>l1_mr</a><br>\n",
    "<a href='#l2_mr'>l2_mr</a><br>\n",
    "<a href='#l3_mr'>l3_mr</a><br>\n",
    "<a href='#branch_mr'>branch_mr</a><br>\n",
    "<a href='#fetch_stall'>fetch_stall</a><br>\n",
    "<a href='#vipi'>vipi</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_list, tot_cyc_list = scaling_plot(metric_data, function=\"\\[SUMMARY\\] .TAU application$\", max=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THREAD_COUNT = 1\n",
    "# func = 'clean_cms_seedtracks'\n",
    "func = 'NULL'\n",
    "cyc_data = select_metric_from_scaling(metric_data, 'PAPI_TOT_CYC')\n",
    "# get_func_level_metric(cyc_data[THREAD_COUNT], avg=True, func=\"LayerOfHits::\").head(20)\n",
    "get_func_level_metric(cyc_data[THREAD_COUNT], avg=True, func=func).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "func = 'NULL'\n",
    "# func = 'helixAtRFromIterativeCCS'\n",
    "# func = 'MultHelixPropTransp'\n",
    "# func = '.TAU application$'\n",
    "cyc_data = select_metric_from_scaling(metric_data, 'PAPI_TOT_CYC')\n",
    "get_func_level_metric(cyc_data[THREAD_COUNT], avg=True, func=func).head(20)\n",
    "\n",
    "\n",
    "# bottom of top ten = 2.1e8\n",
    "# total is 4.4e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THREAD_COUNT = 48\n",
    "# func = 'FindCandidatesCloneEngine'\n",
    "func = 'NULL'\n",
    "cyc_data = select_metric_from_scaling(metric_data, 'PAPI_TOT_CYC')\n",
    "get_func_level_metric(cyc_data[THREAD_COUNT], avg=True, func = func).head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycles per thread for each thread count\n",
    "Here we show load balancing with a series of plots showing the cycle count per thread. We have one plot for each thread count used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_cyc_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_TOT_CYC')\n",
    "\n",
    "for kt in thread_list:\n",
    "    print kt\n",
    "    data = list(thread_cyc_data[kt])\n",
    "    matplotlib.pyplot.bar(range(len(data)), data)\n",
    "    matplotlib.pyplot.ylim(ymax=50000000000) \n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Missrate vs thread count\n",
    "Similar to above these cells show the L1 missrates. In this case we want to get the plotting data for L1 acceses and misses but comupte the miss rate before plotting, so we set plot=False\n",
    "\n",
    "<a href='#top'>top</a><br>\n",
    "\n",
    "<a id='l1_mr'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_list, L1A_data = scaling_plot(metric_data, plot=False, metric='PAPI_LST_INS')\n",
    "thread_list, L1M_data = scaling_plot(metric_data, plot=False, metric='PAPI_L1_TCM')\n",
    "    \n",
    "L1_MR_list = [L1M_data[i] / L1A_data[i] for i in range(len(thread_list))]\n",
    "\n",
    "plt = matplotlib.pyplot.plot(thread_list, L1_MR_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Miss rate by each thread of each thread count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_L1A_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_LST_INS')\n",
    "thread_L1M_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_L1_TCM')\n",
    "\n",
    "MR_data = {}\n",
    "for kt in thread_list:\n",
    "#     print(thread_L1M_data[kt])\n",
    "#     print(thread_L1A_data[kt])\n",
    "    MR_data[kt] = thread_L1M_data[kt] / thread_L1A_data[kt]\n",
    "    \n",
    "for kt in thread_list:\n",
    "    print kt\n",
    "    data = list(MR_data[kt])\n",
    "    matplotlib.pyplot.bar(range(len(data)), data)\n",
    "    matplotlib.pyplot.ylim(ymax=0.05)\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Top 10 bad miss rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_data = select_metric_from_scaling(metric_data, 'DERIVED_L1_MISSRATE')\n",
    "L1_MR_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    L1_MR_dict[n_thr] = filter_libs_out(L1_data[n_thr]).sort_values(by='Exclusive',ascending=False)[[\"Exclusive\"]]\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 1\n",
    "# func = 'NULL'\n",
    "# func = 'FindCandidatesCloneEngine' # NULL for nothing\n",
    "func = 'SelectHitIndices' # NULL for nothing\n",
    "get_func_level_metric(L1_MR_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "\n",
    "get_func_level_metric(L1_MR_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 48\n",
    "get_func_level_metric(L1_MR_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Top 10 bad miss counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_tcm = select_metric_from_scaling(metric_data, 'PAPI_L1_TCM')\n",
    "L1_tcm_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    L1_tcm_dict[n_thr] = filter_libs_out(L1_tcm[n_thr])\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 1\n",
    "# func = 'NULL'\n",
    "# func = 'FindCandidatesCloneEngine' # NULL for nothing\n",
    "func = 'SelectHitIndices' # NULL for nothing\n",
    "get_func_level_metric(L1_tcm_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "get_func_level_metric(L1_tcm_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 48\n",
    "get_func_level_metric(L1_tcm_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Missrate vs thread count\n",
    "Similar to above these cells show the L2 missrates.\n",
    "\n",
    "<a href='#top'>top</a><br>\n",
    "<a id='l2_mr'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_list, L2A_data = scaling_plot(metric_data, plot=False, metric='PAPI_L2_TCA')\n",
    "thread_list, L2M_data = scaling_plot(metric_data, plot=False, metric='PAPI_L2_TCM')\n",
    "    \n",
    "L2_MR_list = [L2M_data[i] / L2A_data[i] for i in range(len(thread_list))]\n",
    "\n",
    "plt = matplotlib.pyplot.plot(thread_list, L2_MR_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_L2A_data = get_thread_level_metric_scaling(select_metric_from_scaling(metric_data, 'PAPI_L2_TCA'))\n",
    "thread_L2M_data = get_thread_level_metric_scaling(select_metric_from_scaling(metric_data, 'PAPI_L2_TCM'))\n",
    "\n",
    "\n",
    "L2_MR_data = {}\n",
    "for kt in thread_list:\n",
    "    L2_MR_data[kt] = thread_L2M_data[kt] / thread_L2A_data[kt]\n",
    "    \n",
    "for kt in thread_list:\n",
    "    print kt\n",
    "    data = list(L2_MR_data[kt])\n",
    "    matplotlib.pyplot.bar(range(len(data)), data)\n",
    "    matplotlib.pyplot.ylim(ymax=0.3)\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Top 10 bad miss rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_data = select_metric_from_scaling(metric_data, 'DERIVED_L2_MISSRATE')\n",
    "L2_MR_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    L2_MR_dict[n_thr] = filter_libs_out(L2_data[n_thr]).sort_values(by='Exclusive',ascending=False)[[\"Exclusive\"]]\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "# func = 'NULL'\n",
    "func = 'FindCandidatesCloneEngine' # NULL for nothing\n",
    "# func = 'SelectHitIndices' # NULL for nothing\n",
    "get_func_level_metric(L1_MR_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "get_func_level_metric(L2_MR_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "get_func_level_metric(L3_MR_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALL CACHE Top 10 bad miss counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_tcm = select_metric_from_scaling(metric_data, 'PAPI_L2_TCM')\n",
    "L2_tcm_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    L2_tcm_dict[n_thr] = filter_libs_out(L2_tcm[n_thr])\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "# func = 'NULL'\n",
    "func = 'FindCandidatesCloneEngine' # NULL for nothing\n",
    "# func = 'SelectHitIndices' # NULL for nothing\n",
    "get_func_level_metric(L1_tcm_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "get_func_level_metric(L2_tcm_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "get_func_level_metric(L3_tcm_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Cache misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "get_func_level_metric(L1_tcm_dict[THREAD_COUNT], func='.TAU application$', inclusive='inclusive', avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "get_func_level_metric(L2_tcm_dict[THREAD_COUNT], func='.TAU application$', inclusive='inclusive', avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "get_func_level_metric(L3_tcm_dict[THREAD_COUNT], func='.TAU application$', inclusive='inclusive', avg=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L3 Missrate vs thread count\n",
    "Similar to above these cells show the L3 missrates.\n",
    "\n",
    "\n",
    "<a href='#top'>top</a><br>\n",
    "<a id='l3_mr'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if application == 'talapas_scaling':\n",
    "    thread_list, LLA_data = scaling_plot(metric_data, plot=False, metric='PAPI_L3_TCA')\n",
    "    thread_list, LLM_data = scaling_plot(metric_data, plot=False, metric='PAPI_L3_TCM')\n",
    "else:\n",
    "    thread_list, LLA_data = scaling_plot(metric_data, plot=False, metric='PAPI_NATIVE_LLC_REFERENCES')\n",
    "    thread_list, LLM_data = scaling_plot(metric_data, plot=False, metric='PAPI_NATIVE_LLC_MISSES')\n",
    "    \n",
    "LL_MR_list = [LLM_data[i] / LLA_data[i] for i in range(len(thread_list))]\n",
    "\n",
    "plt = matplotlib.pyplot.plot(thread_list, LL_MR_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if application == 'talapas_scaling':\n",
    "    thread_LLA_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_L3_TCA')\n",
    "    thread_LLM_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_L3_TCM')\n",
    "else:\n",
    "    thread_LLA_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_NATIVE_LLC_REFERENCES')\n",
    "    thread_LLM_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_NATIVE_LLC_MISSES')\n",
    "\n",
    "\n",
    "LL_MR_data = {}\n",
    "for kt in thread_list:\n",
    "    LL_MR_data[kt] = thread_LLM_data[kt] / thread_LLA_data[kt]\n",
    "\n",
    "def thread_bar_plots(data_dict, t_list, y=-1):\n",
    "    for kt in t_list:\n",
    "        print \"Thread Count: %d\" % kt\n",
    "        data = list(data_dict[kt])\n",
    "        matplotlib.pyplot.bar(range(len(data)), data)\n",
    "        if y != -1:\n",
    "            matplotlib.pyplot.ylim(ymax=y)\n",
    "        matplotlib.pyplot.show()\n",
    "\n",
    "thread_bar_plots(LL_MR_data, thread_list, 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L3 Top 10 bad miss rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L3_data = select_metric_from_scaling(metric_data, 'DERIVED_L3_MISSRATE')\n",
    "L3_MR_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    L3_MR_dict[n_thr] = filter_libs_out(L3_data[n_thr]).sort_values(by='Exclusive',ascending=False)[[\"Exclusive\"]]\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 1\n",
    "# func = 'NULL'\n",
    "# func = 'FindCandidatesCloneEngine' # NULL for nothing\n",
    "func = 'SelectHitIndices' # NULL for nothing\n",
    "get_func_level_metric(L3_MR_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "get_func_level_metric(L3_MR_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 48\n",
    "get_func_level_metric(L3_MR_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L3 Top 10 bad miss counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L3_tcm = select_metric_from_scaling(metric_data, 'PAPI_NATIVE_LLC_MISSES')\n",
    "L3_tcm_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    L3_tcm_dict[n_thr] = filter_libs_out(L1_tcm[n_thr])\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 1\n",
    "# func = 'NULL'\n",
    "# func = 'FindCandidatesCloneEngine' # NULL for nothing\n",
    "func = 'SelectHitIndices' # NULL for nothing\n",
    "get_func_level_metric(L3_tcm_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "get_func_level_metric(L3_tcm_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 48\n",
    "get_func_level_metric(L3_tcm_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branch Missrate vs thread count\n",
    "Similar to above these cells show the rate of misspredicted branches.\n",
    "\n",
    "\n",
    "<a href='#top'>top</a><br>\n",
    "<a id='branch_mr'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_list, BR_INS_data = scaling_plot(metric_data, plot=False, metric='PAPI_BR_INS')\n",
    "thread_list, BR_MSP_data = scaling_plot(metric_data, plot=False, metric='PAPI_BR_MSP')\n",
    "    \n",
    "BR_MR_list = [BR_MSP_data[i] / BR_INS_data[i] for i in range(len(thread_list))]\n",
    "\n",
    "plt = matplotlib.pyplot.plot(thread_list, BR_MR_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branch Miss rate by each thread of each thread count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_BR_INS_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_BR_INS')\n",
    "thread_BR_MSP_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_BR_MSP')\n",
    "\n",
    "MR_data = {}\n",
    "for kt in thread_list:\n",
    "#     print(thread_L1M_data[kt])\n",
    "#     print(thread_L1A_data[kt])\n",
    "    MR_data[kt] = thread_BR_MSP_data[kt] / thread_BR_INS_data[kt]\n",
    "    \n",
    "for kt in thread_list:\n",
    "    print kt\n",
    "    data = list(MR_data[kt])\n",
    "    matplotlib.pyplot.bar(range(len(data)), data)\n",
    "    matplotlib.pyplot.ylim(ymax=0.2)\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branch Top 10 bad miss rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BR_data = select_metric_from_scaling(metric_data, 'DERIVED_BRANCH_MR')\n",
    "BR_MR_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    BR_MR_dict[n_thr] = filter_libs_out(BR_data[n_thr]).sort_values(by='Exclusive',ascending=False)[[\"Exclusive\"]]\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 1\n",
    "func = 'NULL'\n",
    "# func = 'FindCandidatesCloneEngine' # NULL for nothing\n",
    "# func = 'SelectHitIndices' # NULL for nothing\n",
    "get_func_level_metric(BR_MR_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "func = 'NULL'\n",
    "get_func_level_metric(BR_MR_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 48\n",
    "get_func_level_metric(BR_MR_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branch Top 10 bad miss counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BR_msp = select_metric_from_scaling(metric_data, 'PAPI_BR_INS')\n",
    "# BR_msp = select_metric_from_scaling(metric_data, 'PAPI_BR_MSP')\n",
    "BR_msp_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    BR_msp_dict[n_thr] = filter_libs_out(BR_msp[n_thr])\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 1\n",
    "func = 'NULL'\n",
    "# func = 'FindCandidatesCloneEngine' # NULL for nothing\n",
    "# func = 'SelectHitIndices' # NULL for nothing\n",
    "get_func_level_metric(BR_msp_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "get_func_level_metric(BR_msp_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 48\n",
    "func = 'NULL'\n",
    "# func = 'MultHelixPropTransp'\n",
    "get_func_level_metric(BR_msp_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Stall Top 10\n",
    "Includes fetch stalls per tot cyc\n",
    "and raw counts\n",
    "\n",
    "\n",
    "<a href='#top'>top</a><br>\n",
    "<a id='fetch_stall'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_list, FETCH_STALL_data = scaling_plot(metric_data, plot=False, metric='PAPI_NATIVE_FETCH_STALL')\n",
    "thread_list, TOT_CYC_data = scaling_plot(metric_data, plot=False, metric='PAPI_TOT_CYC')\n",
    "    \n",
    "FS_P_CYC_list = [FETCH_STALL_data[i] / TOT_CYC_data[i] for i in range(len(thread_list))]\n",
    "\n",
    "plt = matplotlib.pyplot.plot(thread_list, FS_P_CYC_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fetch stalls per total cyc by each thread of each thread count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_TOT_CYC_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_TOT_CYC')\n",
    "thread_FETCH_STL_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_NATIVE_FETCH_STALL')\n",
    "\n",
    "FS_P_CYC_data = {}\n",
    "for kt in thread_list:\n",
    "#     print(thread_L1M_data[kt])\n",
    "#     print(thread_L1A_data[kt])\n",
    "    FS_P_CYC_data[kt] = thread_FETCH_STL_data[kt] / thread_TOT_CYC_data[kt]\n",
    "    \n",
    "for kt in thread_list:\n",
    "    print kt\n",
    "    data = list(FS_P_CYC_data[kt])\n",
    "    matplotlib.pyplot.bar(range(len(data)), data)\n",
    "    matplotlib.pyplot.ylim(ymax=0.2)\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch stall per cyc top ten bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSTC_data = select_metric_from_scaling(metric_data, 'DERIVED_RATIO_FETCH_STL_TOT_CYC')\n",
    "FSTC_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    FSTC_dict[n_thr] = filter_libs_out(FSTC_data[n_thr]).sort_values(by='Exclusive',ascending=False)[[\"Exclusive\"]]\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 1\n",
    "func = 'NULL'\n",
    "# func = 'FindCandidatesCloneEngine' # NULL for nothing\n",
    "# func = 'SelectHitIndices' # NULL for nothing\n",
    "get_func_level_metric(FSTC_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "\n",
    "get_func_level_metric(FSTC_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 48\n",
    "get_func_level_metric(FSTC_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Stall count top 10 lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_stall = select_metric_from_scaling(metric_data, 'PAPI_NATIVE_FETCH_STALL')\n",
    "fetch_stall_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    fetch_stall_dict[n_thr] = filter_libs_out(fetch_stall[n_thr])\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 1\n",
    "func = 'NULL'\n",
    "# func = 'FindCandidatesCloneEngine' # NULL for nothing\n",
    "# func = 'SelectHitIndices' # NULL for nothing\n",
    "get_func_level_metric(fetch_stall_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "get_func_level_metric(fetch_stall_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 48\n",
    "get_func_level_metric(fetch_stall_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Ins per Ins Top 10 counts\n",
    "\n",
    "\n",
    "<a href='#top'>top</a><br>\n",
    "<a id='vipi'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_ratio = select_metric_from_scaling(metric_data, 'DERIVED_VIPI')\n",
    "vector_ratio_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    vector_ratio_dict[n_thr] = filter_libs_out(vector_ratio[n_thr])\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 1\n",
    "func = 'NULL'\n",
    "# func = 'FindCandidatesCloneEngine' # NULL for nothing\n",
    "# func = 'SelectHitIndices' # NULL for nothing\n",
    "get_func_level_metric(vector_ratio_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "get_func_level_metric(vector_ratio_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 48\n",
    "get_func_level_metric(vector_ratio_dict[THREAD_COUNT], func=func, avg=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_metrics_2(metric_dict,inc_exc='Inclusive'):\n",
    "    if inc_exc == 'Inclusive': todrop = 'Exclusive'\n",
    "    else: todrop = 'Inclusive'\n",
    "    \n",
    "    for m in metric_dict:\n",
    "        if not m == 'METADATA':\n",
    "            print metric_dict[m].index\n",
    "            metric_dict[m].index = metric_dict[m].index.droplevel()\n",
    "            print metric_dict[m].index\n",
    "    \n",
    "    alldata = metric_dict['PAPI_TOT_CYC'].copy().drop(['Calls','Subcalls',todrop,'ProfileCalls'], axis=1)\n",
    "    alldata['PAPI_TOT_CYC'] = alldata[inc_exc]\n",
    "    alldata.drop([inc_exc],axis=1,inplace=True)\n",
    "\n",
    "    for x in metric_dict.keys():\n",
    "        if x in ['PAPI_TOT_CYC','METADATA']: continue\n",
    "        alldata[x] = metric_dict[x][inc_exc]\n",
    "    return alldata\n",
    "                \n",
    "data = dict(metric_data)\n",
    "THREAD_COUNT = 8\n",
    "metric = 'DERIVED_VIPI'\n",
    "\n",
    "\n",
    "data[8]['PAPI_TOT_CYC'].sort_values(by='Inclusive',ascending=False).head(10)\n",
    "\n",
    "\n",
    "# alldata = combine_metrics_2(data[THREAD_COUNT],inc_exc='Exclusive')\n",
    "\n",
    "\n",
    "# for m in metric_data[THREAD_COUNT].keys():\n",
    "#     if (not m == 'METADATA') and (not m == 'PAPI_TOT_CYC') and (not m == metric): alldata.drop([m],axis=1,inplace=True)\n",
    "\n",
    "# metric_data[THREAD_COUNT][metric]\n",
    "# metric_data[THREAD_COUNT]['PAPI_TOT_CYC']\n",
    "# alldata.sort_values(by='DERIVED_VIPI',ascending=False)\n",
    "# cyc_data = select_metric_from_scaling(metric_data, 'PAPI_TOT_CYC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,d = scaling_plot(metric_data, inclusive=True, plot=True, function=\"MultHelixPropTransp\", metric='DERIVED_L1_MISSRATE', max=False)\n",
    "print d[8]\n",
    "t,d = scaling_plot(metric_data, inclusive=True, plot=True, function=\"MultHelixPropTransp\", metric='DERIVED_L1_MISSRATE', max=True)\n",
    "print d[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Resource Stalls vs thread count\n",
    "Similar to above these cells show the Resource Stalls. In this case we have nothing to compute, so we simply call the function. Future work includes exploring the different types of stalls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_list, res_stall_data = scaling_plot(metric_data, metric='PAPI_RES_STL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_stall_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_RES_STL')\n",
    "thread_bar_plots(thread_stall_data, thread_list, 4000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = combine_metrics(metric_data[32],'Inclusive')\n",
    "cm = sns.light_palette(\"yellow\", as_cmap=True)\n",
    "correlations_pearson = alldata.corr('pearson').fillna(0)    # Other methods: 'kendall', 'spearman'\n",
    "correlations_pearson.style.format(\"{:.2%}\").background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
