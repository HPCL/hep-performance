{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Analysis\n",
    "\n",
    "Author: Brain Gravelle (gravelle@cs.uoregon.edu)\n",
    "\n",
    "\n",
    "All this is using the taucmdr python libraries from paratools\n",
    "http://taucommander.paratools.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "This section imports necessary libraies, the metrics.py and utilities.py files and sets up the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A couple of scripts to set the environent and import data from a .tau set of results\n",
    "from utilities import *\n",
    "from metrics import *\n",
    "# Plotting, notebook settings:\n",
    "%matplotlib inline  \n",
    "#plt.rcParams.update({'font.size': 16})\n",
    "import numbers\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.float_format', lambda x: '%.2e' % x)\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('max_colwidth', 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data\n",
    "\n",
    "TAU Commander uses TAU to run the application and measure it using runtime sampling techniques (similar to Intel VTune). Many customization options are available. For example, we may consider each function regardless of calling context, or we may decide to enable callpath profiling to see each context separately.\n",
    "\n",
    "From the talapas_scaling application the following experiments are available. These use Talapas (with 28 thread Broadwell processors) and the build-ce (realistic) option for mkFit. The first six experiments use the --num-thr option to set the thread count which is intended to perform threading within the events. the last two add the --num-ev-thr option to set the event threads, so that all threads are used to process events in parallel and each event is processed by a single thread. \n",
    "* manual_scaling_Large_talapas\t\t\n",
    "* manual_scaling_Large_talapas_fullnode\t\n",
    "* manual_scaling_TTbar70_talapas\t\t\n",
    "* manual_scaling_TTbar70_talapas_fullnode\n",
    "* manual_scaling_TTbar35_talapas\n",
    "* manual_scaling_TTbar35_talapas_fullnode\n",
    "* ev_thr_scaling_Large_talapas\n",
    "* ev_thr_scaling_Large_talapas_fullnode\n",
    "\n",
    "Additionally available in the cori_scaling application are the following. These were run on NERSC's Cori on the KNL with the default memory settings (quad - 1 NUMA domain, cache - MCDRAM as direct mapped cache). See http://www.nersc.gov/users/computational-systems/cori/running-jobs/advanced-running-jobs-options/ for more info on the KNL modes. Similar to the talapas scaling they use the build-ce option and threading within each event.\n",
    "* manual_scaling_TTbar35\n",
    "* manual_scaling_TTbar70\n",
    "* manual_scaling_Large\n",
    "* mixed_thr_scaling_Large\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Scaling Data\n",
    "Here we import the data. In this case we are using Cori data from the experiments with the threads working within each event using the TTbar35 file. Note that this box will take 10 or more minutes to run; please go enjoy a coffee while you wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 889 trials with 696 errors\n",
      "\n",
      "\n",
      "[32, 48, 2, 3, 8, 16, 56]\n"
     ]
    }
   ],
   "source": [
    "# application = \"talapas_scaling\"\n",
    "# experiment  = \"manual_scaling_TTbar70_talapas\"\n",
    "# experiment  = \"manual_scaling_Large_talapas\"\n",
    "# experiment = \"ev_thr_scaling_Large_talapas\"\n",
    "\n",
    "application = \"talapas_no_throttle_scaling\"\n",
    "experiment  = \"manual_scaling_Large_talapas_fullnode\"\n",
    "\n",
    "\n",
    "# application = \"cori_scaling\"\n",
    "# experiment  = \"manual_scaling_TTbar35\"\n",
    "# experiment  = \"manual_scaling_TTbar70\"\n",
    "# experiment  = \"manual_scaling_Large\"\n",
    "# experiment  = \"mixed_thr_scaling_Large\"\n",
    "\n",
    "path = \".tau/\" + application + \"/\" + experiment + \"/\"\n",
    "# note that this function takes a long time to run, so only rerun if you must\n",
    "\n",
    "metric_data = get_pandas_scaling(path, callpaths=True)\n",
    "print(metric_data.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 48, 2, 3, 8, 16, 56]\n",
      "PAPI_DP_OPS\n",
      "PAPI_TLB_DM\n",
      "DERIVED_L1_MISSRATE\n",
      "PAPI_VEC_DP\n",
      "PAPI_L3_TCM\n",
      "PAPI_RES_STL\n",
      "PAPI_SP_OPS\n",
      "PAPI_LST_INS\n",
      "PAPI_NATIVE_UOPS_RETIRED:STALL_CYCLES\n",
      "PAPI_NATIVE_FP_ARITH:256B_PACKED_SINGLE\n",
      "PAPI_VEC_SP\n",
      "PAPI_NATIVE_FP_ARITH:256B_PACKED_DOUBLE\n",
      "PAPI_L1_TCM\n",
      "PAPI_BR_MSP\n",
      "PAPI_TOT_CYC\n",
      " \n",
      "PAPI_NATIVE_MACHINE_CLEARS:COUNT\n",
      "PAPI_TLB_IM\n",
      "PAPI_NATIVE_FP_ARITH:128B_PACKED_DOUBLE\n",
      "PAPI_L3_TCM\n",
      "PAPI_NATIVE_RESOURCE_STALLS:SB\n",
      " \n",
      "PAPI_L2_TCA\n",
      "PAPI_TLB_DM\n",
      "PAPI_VEC_DP\n",
      "PAPI_L2_TCM\n",
      "DERIVED_CPI\n",
      "PAPI_NATIVE_FP_ARITH:256B_PACKED_SINGLE\n",
      "PAPI_L1_TCM\n",
      "PAPI_BR_MSP\n",
      "PAPI_NATIVE_MACHINE_CLEARS:COUNT\n",
      "PAPI_DP_OPS\n",
      "PAPI_RES_STL\n",
      "PAPI_TOT_INS\n",
      "PAPI_VEC_SP\n",
      "PAPI_L3_TCA\n",
      "PAPI_TLB_IM\n",
      "PAPI_NATIVE_FP_ARITH:128B_PACKED_SINGLE\n",
      "DERIVED_L1_MISSRATE\n",
      "PAPI_L3_TCM\n",
      "DERIVED_L3_MISSRATE\n",
      "PAPI_NATIVE_FP_ARITH:SCALAR_DOUBLE\n",
      "PAPI_NATIVE_RESOURCE_STALLS:SB\n",
      "PAPI_NATIVE_FP_ARITH:SCALAR_SINGLE\n",
      "PAPI_BR_INS\n",
      "DERIVED_L2_MISSRATE\n",
      "PAPI_NATIVE_FP_ARITH:128B_PACKED_DOUBLE\n",
      "DERIVED_IPC\n",
      "PAPI_LST_INS\n",
      "PAPI_NATIVE_UOPS_RETIRED:STALL_CYCLES\n",
      "PAPI_SP_OPS\n",
      "PAPI_NATIVE_FP_ARITH:256B_PACKED_DOUBLE\n",
      "PAPI_TOT_CYC\n",
      " \n",
      "PAPI_L2_TCM\n",
      " \n",
      "PAPI_NATIVE_FP_ARITH:SCALAR_DOUBLE\n",
      "PAPI_NATIVE_MACHINE_CLEARS:COUNT\n",
      "PAPI_TLB_IM\n",
      "DERIVED_IPC\n",
      "DERIVED_L1_MISSRATE\n",
      "PAPI_VEC_DP\n",
      "PAPI_L2_TCM\n",
      "PAPI_TOT_INS\n",
      "DERIVED_CPI\n",
      "PAPI_VEC_SP\n",
      "PAPI_LST_INS\n",
      "PAPI_NATIVE_RESOURCE_STALLS:SB\n",
      "PAPI_SP_OPS\n",
      "PAPI_NATIVE_FP_ARITH:SCALAR_SINGLE\n",
      "PAPI_L1_TCM\n",
      "PAPI_BR_MSP\n",
      "PAPI_TOT_CYC\n",
      " \n",
      "PAPI_BR_INS\n",
      "PAPI_NATIVE_MACHINE_CLEARS:COUNT\n",
      "PAPI_TLB_IM\n",
      "PAPI_NATIVE_FP_ARITH:256B_PACKED_DOUBLE\n",
      "DERIVED_IPC\n",
      "PAPI_NATIVE_FP_ARITH:128B_PACKED_DOUBLE\n",
      "DERIVED_L2_MISSRATE\n",
      "PAPI_L3_TCM\n",
      "PAPI_L2_TCM\n",
      "PAPI_TOT_INS\n",
      "PAPI_L2_TCA\n",
      "PAPI_NATIVE_FP_ARITH:SCALAR_DOUBLE\n",
      "PAPI_NATIVE_UOPS_RETIRED:STALL_CYCLES\n",
      "PAPI_NATIVE_FP_ARITH:256B_PACKED_SINGLE\n",
      "DERIVED_CPI\n",
      "PAPI_BR_MSP\n",
      "PAPI_TOT_CYC\n",
      "PAPI_NATIVE_FP_ARITH:SCALAR_SINGLE\n",
      " \n",
      "PAPI_NATIVE_MACHINE_CLEARS:COUNT\n",
      "PAPI_NATIVE_FP_ARITH:128B_PACKED_SINGLE\n",
      "PAPI_L2_TCM\n",
      "PAPI_NATIVE_UOPS_RETIRED:STALL_CYCLES\n",
      "PAPI_TOT_CYC\n",
      " \n"
     ]
    }
   ],
   "source": [
    "if application == \"talapas_scaling\":\n",
    "    metric_data = remove_erroneous_threads(metric_data,  [1, 2, 8, 16, 32, 48, 56])\n",
    "elif application == \"cori_scaling\":\n",
    "    metric_data = remove_erroneous_threads(metric_data,  [1, 4, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256])\n",
    "\n",
    "print metric_data.keys()\n",
    "for kt in metric_data:\n",
    "    print_available_metrics(metric_data[kt])\n",
    "    print \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAPI_L2_TCA\n",
      "PAPI_TLB_DM\n",
      "PAPI_VEC_DP\n",
      "PAPI_L2_TCM\n",
      "DERIVED_CPI\n",
      "PAPI_NATIVE_FP_ARITH:256B_PACKED_SINGLE\n",
      "PAPI_L1_TCM\n",
      "PAPI_BR_MSP\n",
      "PAPI_NATIVE_MACHINE_CLEARS:COUNT\n",
      "PAPI_DP_OPS\n",
      "PAPI_RES_STL\n",
      "PAPI_TOT_INS\n",
      "PAPI_VEC_SP\n",
      "PAPI_L3_TCA\n",
      "PAPI_TLB_IM\n",
      "PAPI_NATIVE_FP_ARITH:128B_PACKED_SINGLE\n",
      "DERIVED_L1_MISSRATE\n",
      "PAPI_L3_TCM\n",
      "DERIVED_L3_MISSRATE\n",
      "PAPI_NATIVE_FP_ARITH:SCALAR_DOUBLE\n",
      "PAPI_NATIVE_RESOURCE_STALLS:SB\n",
      "PAPI_NATIVE_FP_ARITH:SCALAR_SINGLE\n",
      "PAPI_BR_INS\n",
      "DERIVED_L2_MISSRATE\n",
      "PAPI_NATIVE_FP_ARITH:128B_PACKED_DOUBLE\n",
      "DERIVED_IPC\n",
      "PAPI_LST_INS\n",
      "PAPI_NATIVE_UOPS_RETIRED:STALL_CYCLES\n",
      "PAPI_SP_OPS\n",
      "PAPI_NATIVE_FP_ARITH:256B_PACKED_DOUBLE\n",
      "PAPI_TOT_CYC\n"
     ]
    }
   ],
   "source": [
    "print_available_metrics(metric_data[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAU_MAX_THREADS                                    112\n",
      "TAU_CUDA_BINARY_EXE                                None\n",
      "TAU_MEASURE_TAU                                    off\n",
      "Memory Size                                        131916412 kB\n",
      "TAU_TRACK_SIGNALS                                  off\n",
      "TAU_TRACK_IO_PARAMS                                off\n",
      "CPU MHz                                            1200.062\n",
      "Local Time                                         2018-04-30T22:08:35-07:00\n",
      "CPU Type                                           Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz\n",
      "TAU_OUTPUT_CUDA_CSV                                off\n",
      "TAU_EBS_INCLUSIVE                                  0 usec\n",
      "Node Name                                          n072\n",
      "TAU_CALLPATH_DEPTH                                 100\n",
      "CPU Cores                                          14\n",
      "OS Machine                                         x86_64\n",
      "TAU_SAMPLING                                       on\n",
      "Cache Size                                         35840 KB\n",
      "TAU_PAPI_MULTIPLEXING                              off\n",
      "TAU_EBS_KEEP_UNRESOLVED_ADDR                       off\n",
      "TAU_THROTTLE                                       off\n",
      "TAU Architecture                                   default\n",
      "TAU_COMPENSATE                                     off\n",
      "TAU_CALLSITE_DEPTH                                 1\n",
      "TAU_SHOW_MEMORY_FUNCTIONS                          off\n",
      "OS Version                                         #1 SMP Sun Jan 14 10:36:03 EST 2018\n",
      "Starting Timestamp                                 1525151315079852\n",
      "TAU_SIGNALS_GDB                                    off\n",
      "TAU Version                                        2.27-git\n",
      "TAU_TRACK_MEMORY_LEAKS                             off\n",
      "TAU_MEMDBG_PROTECT_FREE                            off\n",
      "TAU Config                                          -tag=05c9fa46 -arch=x86_64 -cc=icc -c++=icpc -fortran=intel -bfd=/gpfs/projects/hpcl/shared/taucmdr-enterprise/system/binutils/7af21441 -papi=/packages/papi/5.5.1 -unwind=/gpfs/projects/hpcl/shared/taucmdr-enterprise/system/libunwind/743af2e8 -tbb -useropt=-O2#-g#-DTAU_MAX_THREADS=112#-DTAU_MAX_METRICS=2#-DTAU_MAX_COUNTERS=2\n",
      "TAU_EBS_SAMPLES_DROPPED_TAU_3                      0\n",
      "TAU_EBS_SAMPLES_DROPPED_TAU_2                      0\n",
      "TAU_EBS_SAMPLES_DROPPED_TAU_1                      0\n",
      "TAU_EBS_SAMPLES_DROPPED_TAU_0                      0\n",
      "TAU_EBS_SAMPLES_DROPPED_TAU_7                      0\n",
      "TAU_EBS_SAMPLES_DROPPED_TAU_6                      0\n",
      "TAU_EBS_SAMPLES_DROPPED_TAU_5                      0\n",
      "TAU_EBS_SAMPLES_DROPPED_TAU_4                      0\n",
      "TAU_OPENMP_RUNTIME_EVENTS                          on\n",
      "TAU_BFD_LOOKUP                                     on\n",
      "TAU_EBS_UNWIND_DEPTH                               10\n",
      "TAU_MEMDBG_PROTECT_BELOW                           off\n",
      "TAU_EBS_PERIOD                                     10000\n",
      "OS Name                                            Linux\n",
      "Hostname                                           n072\n",
      "Metric Name                                        TIME\n",
      "Timestamp                                          1525151315097131\n",
      "TAU_TRACK_CUDA_SASS                                off\n",
      "TAU_TRACK_UNIFIED_MEMORY                           off\n",
      "username                                           bgravell\n",
      "TAU_OPENMP_RUNTIME                                 on\n",
      "TAU_TRACE_FORMAT                                   tau\n",
      "TAU_OPENMP_RUNTIME_STATES                          off\n",
      "pid                                                44315\n",
      "TAU_MEMDBG_PROTECT_ABOVE                           off\n",
      "Ending Timestamp                                   1525151419416928\n",
      "TAU_PROFILE_FORMAT                                 profile\n",
      "Executable                                         /gpfs/projects/hpcl/bgravell/mictest_sampling/mkFit/mkFit\n",
      "TAU_TRACK_CUDA_INSTRUCTIONS                        None\n",
      "TAU Makefile                                       /gpfs/projects/hpcl/shared/taucmdr-enterprise/system/tau/tau-2.27/x86_64/lib/Makefile.tau-05c9fa46-icpc-papi-tbb\n",
      "TAU_TRACK_HEADROOM                                 off\n",
      "CPU Vendor                                         GenuineIntel\n",
      "TAU_PROFILE                                        on\n",
      "TAU_TRACK_CUDA_CDP                                 off\n",
      "Command Line                                       mkFit --cmssw-n2seeds --input-file /projects/hpcl/bgravell/mictest_sampling/memoryFile.fv3.clean.writeAll.recT.072617.bin --build-ce --num-thr 8 --num-thr-ev 8 --num-events 4550 --silent\n",
      "TAU_TRACK_HEAP                                     off\n",
      "TAU_CALLPATH                                       on\n",
      "tid                                                44315\n",
      "TAU_TRACE                                          off\n",
      "TAU_EBS_SAMPLES_DROPPED_SUSPENDED_0                0\n",
      "TAU_EBS_SAMPLES_DROPPED_SUSPENDED_1                0\n",
      "TAU_EBS_SAMPLES_DROPPED_SUSPENDED_2                0\n",
      "TAU_EBS_SAMPLES_DROPPED_SUSPENDED_3                0\n",
      "TAU_EBS_SAMPLES_DROPPED_SUSPENDED_4                0\n",
      "TAU_EBS_SAMPLES_DROPPED_SUSPENDED_5                0\n",
      "TAU_EBS_SAMPLES_DROPPED_SUSPENDED_6                0\n",
      "TAU_EBS_SAMPLES_DROPPED_SUSPENDED_7                0\n",
      "TAU_IBM_BG_HWP_COUNTERS                            off\n",
      "UTC Time                                           2018-05-01T05:08:35Z\n",
      "CWD                                                /gpfs/projects/hpcl/bgravell/mictest_sampling/.tau/talapas_no_throttle_scaling/manual_scaling_Large_talapas_fullnode/787\n",
      "TAU_TRACK_MEMORY_FOOTPRINT                         off\n",
      "TAU_EBS_UNWIND                                     on\n",
      "TAU_CUPTI_API                                      runtime\n",
      "OS Release                                         3.10.0-693.17.1.el7.x86_64\n",
      "TAU_EBS_SAMPLES_TAKEN_1                            10387\n",
      "TAU_EBS_SAMPLES_TAKEN_0                            10387\n",
      "TAU_EBS_SAMPLES_TAKEN_3                            10387\n",
      "TAU_EBS_SAMPLES_TAKEN_2                            10387\n",
      "TAU_EBS_SAMPLES_TAKEN_5                            10387\n",
      "TAU_EBS_SAMPLES_TAKEN_4                            10387\n",
      "TAU_EBS_SAMPLES_TAKEN_7                            10387\n",
      "TAU_EBS_SAMPLES_TAKEN_6                            10387\n"
     ]
    }
   ],
   "source": [
    "print_metadata(metric_data[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding metrics\n",
    "\n",
    "metrics are available in metrics.py. At this time the following can be added:\n",
    "* add_IPC(metrics)          - Instructions per Cycle\n",
    "* add_CPI(metrics)          - Cycles per instruction\n",
    "* add_VIPC(metrics)         - vector instructions per cycle\n",
    "* add_VIPI(metrics)         - vector instructions per instruction (i.e. fraction of total)\n",
    "* add_L1_missrate(metrics)  - miss rate for L1 cache\n",
    "\n",
    "for scaling data please use the add_metric_to_scaling_data(data, metric_func) function to add a metric\n",
    "\n",
    "Here we add some predeefined metrics and print the top 10 functions with the best IPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR adding CPI to metric dictionary\n",
      "ERROR adding CPI to metric dictionary\n",
      "ERROR adding CPI to metric dictionary\n",
      "ERROR adding CPI to metric dictionary\n",
      "ERROR adding metric to thread count: 32\n",
      "ERROR adding metric to thread count: 3\n",
      "ERROR adding metric to thread count: 48\n",
      "ERROR adding metric to thread count: 56\n",
      "ERROR adding IPC to metric dictionary\n",
      "ERROR adding IPC to metric dictionary\n",
      "ERROR adding IPC to metric dictionary\n",
      "ERROR adding IPC to metric dictionary\n",
      "ERROR adding metric to thread count: 32\n",
      "ERROR adding metric to thread count: 3\n",
      "ERROR adding metric to thread count: 48\n",
      "ERROR adding metric to thread count: 56\n",
      "ERROR adding L1 MR to metric dictionary\n",
      "ERROR adding L1 MR to metric dictionary\n",
      "ERROR adding L1 MR to metric dictionary\n",
      "ERROR adding L1 MR to metric dictionary\n",
      "ERROR adding metric to thread count: 16\n",
      "ERROR adding metric to thread count: 3\n",
      "ERROR adding metric to thread count: 48\n",
      "ERROR adding metric to thread count: 56\n",
      "ERROR adding L2 MR to metric dictionary\n",
      "ERROR adding L2 MR to metric dictionary\n",
      "ERROR adding L2 MR to metric dictionary\n",
      "ERROR adding L2 MR to metric dictionary\n",
      "ERROR adding L2 MR to metric dictionary\n",
      "ERROR adding metric to thread count: 32\n",
      "ERROR adding metric to thread count: 3\n",
      "ERROR adding metric to thread count: 8\n",
      "ERROR adding metric to thread count: 48\n",
      "ERROR adding metric to thread count: 56\n",
      "ERROR adding L3 MR to metric dictionary\n",
      "ERROR adding L3 MR to metric dictionary\n",
      "ERROR adding L3 MR to metric dictionary\n",
      "ERROR adding L3 MR to metric dictionary\n",
      "ERROR adding L3 MR to metric dictionary\n",
      "ERROR adding L3 MR to metric dictionary\n",
      "ERROR adding metric to thread count: 32\n",
      "ERROR adding metric to thread count: 16\n",
      "ERROR adding metric to thread count: 3\n",
      "ERROR adding metric to thread count: 8\n",
      "ERROR adding metric to thread count: 48\n",
      "ERROR adding metric to thread count: 56\n",
      "PAPI_DP_OPS\n",
      "PAPI_TLB_DM\n",
      "DERIVED_L1_MISSRATE\n",
      "PAPI_VEC_DP\n",
      "PAPI_L3_TCM\n",
      "PAPI_RES_STL\n",
      "PAPI_SP_OPS\n",
      "PAPI_LST_INS\n",
      "PAPI_NATIVE_UOPS_RETIRED:STALL_CYCLES\n",
      "PAPI_NATIVE_FP_ARITH:256B_PACKED_SINGLE\n",
      "PAPI_VEC_SP\n",
      "PAPI_NATIVE_FP_ARITH:256B_PACKED_DOUBLE\n",
      "PAPI_L1_TCM\n",
      "PAPI_BR_MSP\n",
      "PAPI_TOT_CYC\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bf40fa26e7da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint_available_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmetric_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DERIVED_IPC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Inclusive'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "add_metric_to_scaling_data(metric_data, add_CPI)\n",
    "add_metric_to_scaling_data(metric_data, add_IPC)\n",
    "add_metric_to_scaling_data(metric_data, add_L1_missrate)\n",
    "add_metric_to_scaling_data(metric_data, add_L2_missrate)\n",
    "if application == 'cori_scaling': llc = True\n",
    "else: llc = False\n",
    "add_metric_to_scaling_data(metric_data, add_L3_missrate, llc)\n",
    "print_available_metrics(metric_data, scaling=True)\n",
    "\n",
    "metric_data[1]['DERIVED_IPC'].sort_values(by='Inclusive',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Results\n",
    "\n",
    "In this section we demo some scaling results with several different metrics.\n",
    "\n",
    "We use the scaling plot function to plot the data vs thread count.\n",
    "scaling_plot(data, inclusive=True, plot=True, function=\"\\[SUMMARY\\] .TAU application$\", metric='PAPI_TOT_CYC', max=False)\n",
    "* data = the full dictionary of scaling data \n",
    "* inclusive = determines if the inclusive data or exclusive data will be used\n",
    "* plot = true makes a plot false does not\n",
    "* function = the string that will be searched for to plot. Default looks at the whole application\n",
    "* metric = the metric choosen from the above list\n",
    "* max = use the max value or average value across the threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling with total cycles vs the thread count\n",
    "Here we plot the cycle count for each thread count as a proxy for execution time. We use the max cycle count rather than the average as this number will limit the time of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_list, tot_cyc_list = scaling_plot(metric_data, function=\"\\[SUMMARY\\] .TAU application$\", max=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycles per thread for each thread count\n",
    "Here we show load balancing with a series of plots showing the cycle count per thread. We have one plot for each thread count used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_cyc_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_TOT_CYC')\n",
    "\n",
    "for kt in thread_list:\n",
    "    print kt\n",
    "    data = list(thread_cyc_data[kt])\n",
    "    matplotlib.pyplot.bar(range(len(data)), data)\n",
    "    matplotlib.pyplot.ylim(ymax=50000000000) \n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Missrate vs thread count\n",
    "Similar to above these cells show the L1 missrates. In this case we want to get the plotting data for L1 acceses and misses but comupte the miss rate before plotting, so we set plot=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_list, L1A_data = scaling_plot(metric_data, plot=False, metric='PAPI_LST_INS')\n",
    "thread_list, L1M_data = scaling_plot(metric_data, plot=False, metric='PAPI_L1_TCM')\n",
    "    \n",
    "L1_MR_list = [L1M_data[i] / L1A_data[i] for i in range(len(thread_list))]\n",
    "\n",
    "plt = matplotlib.pyplot.plot(thread_list, L1_MR_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Miss rate by each thread of each thread count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_L1A_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_LST_INS')\n",
    "thread_L1M_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_L1_TCM')\n",
    "\n",
    "MR_data = {}\n",
    "for kt in thread_list:\n",
    "#     print(thread_L1M_data[kt])\n",
    "#     print(thread_L1A_data[kt])\n",
    "    MR_data[kt] = thread_L1M_data[kt] / thread_L1A_data[kt]\n",
    "    \n",
    "for kt in thread_list:\n",
    "    print kt\n",
    "    data = list(MR_data[kt])\n",
    "    matplotlib.pyplot.bar(range(len(data)), data)\n",
    "    matplotlib.pyplot.ylim(ymax=0.05)\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Top 10 bad miss rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_data = select_metric_from_scaling(metric_data, 'DERIVED_L1_MISSRATE')\n",
    "L1_MR_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    L1_MR_dict[n_thr] = filter_libs_out(L1_data[n_thr]).sort_values(by='Inclusive',ascending=False)[[\"Inclusive\"]]\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THREAD_COUNT = 8\n",
    "# L1_MR_dict[THREAD_COUNT].head(10)\n",
    "\n",
    "get_func_level_metric(L1_MR_dict[THREAD_COUNT], avg=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THREAD_COUNT = 32\n",
    "# L1_MR_dict[THREAD_COUNT].head(10)\n",
    "\n",
    "get_func_level_metric(L1_MR_dict[THREAD_COUNT], avg=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THREAD_COUNT = 80\n",
    "# L1_MR_dict[THREAD_COUNT].head(10)\n",
    "\n",
    "get_func_level_metric(L1_MR_dict[THREAD_COUNT], avg=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THREAD_COUNT = 208\n",
    "L1_MR_dict[THREAD_COUNT].head(10)\n",
    "# TODO sum over all threads\n",
    "# Average too\n",
    "\n",
    "cyc_data = select_metric_from_scaling(metric_data, 'PAPI_TOT_CYC')\n",
    "\n",
    "def get_func_level_metric(data, inclusive=True, avg=True, func = 'NULL'):\n",
    "    '''\n",
    "    data is a panda dataframe of one metric and one thread count\n",
    "    returns a panda series of the metric averaged or summed over each thread\n",
    "    note: for certain derived metrics (i.e. ratios) this won't work because it sums\n",
    "    '''\n",
    "    if inclusive: which='Inclusive'\n",
    "    else: which='Exclusive'\n",
    "        \n",
    "    group_data = data.groupby(['region'])[[which]]\n",
    "\n",
    "    if avg:\n",
    "        metric_list = group_data.mean().sort_values(by=which,ascending=False)[[which]]\n",
    "    else:\n",
    "        metric_list = group_data.sum().sort_values(by=which,ascending=False)[[which]]\n",
    "\n",
    "    if not func == 'NULL':\n",
    "        metric_list = metric_list[metric_list.index.get_level_values('region').str.contains(func)][[which]]\n",
    "\n",
    "    return metric_list\n",
    "\n",
    "get_func_level_metric(cyc_data[8], avg=False, func='MkFinder::SelectHitIndices').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Missrate vs thread count\n",
    "Similar to above these cells show the L2 missrates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_list, L2A_data = scaling_plot(metric_data, plot=False, metric='PAPI_L2_TCA')\n",
    "thread_list, L2M_data = scaling_plot(metric_data, plot=False, metric='PAPI_L2_TCM')\n",
    "    \n",
    "L2_MR_list = [L2M_data[i] / L2A_data[i] for i in range(len(thread_list))]\n",
    "\n",
    "plt = matplotlib.pyplot.plot(thread_list, L2_MR_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_L2A_data = get_thread_level_metric_scaling(select_metric_from_scaling(metric_data, 'PAPI_L2_TCA'))\n",
    "thread_L2M_data = get_thread_level_metric_scaling(select_metric_from_scaling(metric_data, 'PAPI_L2_TCM'))\n",
    "\n",
    "\n",
    "L2_MR_data = {}\n",
    "for kt in thread_list:\n",
    "    L2_MR_data[kt] = thread_L2M_data[kt] / thread_L2A_data[kt]\n",
    "    \n",
    "for kt in thread_list:\n",
    "    print kt\n",
    "    data = list(L2_MR_data[kt])\n",
    "    matplotlib.pyplot.bar(range(len(data)), data)\n",
    "    matplotlib.pyplot.ylim(ymax=0.3)\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Top 10 bad miss rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_data = select_metric_from_scaling(metric_data, 'DERIVED_L2_MISSRATE')\n",
    "L2_MR_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    L2_MR_dict[n_thr] = filter_libs_out(L2_data[n_thr]).sort_values(by='Inclusive',ascending=False)[[\"Inclusive\"]]\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THREAD_COUNT = 16\n",
    "L2_MR_dict[THREAD_COUNT].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L3 Missrate vs thread count\n",
    "Similar to above these cells show the L3 missrates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if application == 'talapas_scaling':\n",
    "    thread_list, LLA_data = scaling_plot(metric_data, plot=False, metric='PAPI_L3_TCA')\n",
    "    thread_list, LLM_data = scaling_plot(metric_data, plot=False, metric='PAPI_L3_TCM')\n",
    "else:\n",
    "    thread_list, LLA_data = scaling_plot(metric_data, plot=False, metric='PAPI_NATIVE_LLC_REFERENCES')\n",
    "    thread_list, LLM_data = scaling_plot(metric_data, plot=False, metric='PAPI_NATIVE_LLC_MISSES')\n",
    "    \n",
    "LL_MR_list = [LLM_data[i] / LLA_data[i] for i in range(len(thread_list))]\n",
    "\n",
    "plt = matplotlib.pyplot.plot(thread_list, LL_MR_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if application == 'talapas_scaling':\n",
    "    thread_LLA_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_L3_TCA')\n",
    "    thread_LLM_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_L3_TCM')\n",
    "else:\n",
    "    thread_LLA_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_NATIVE_LLC_REFERENCES')\n",
    "    thread_LLM_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_NATIVE_LLC_MISSES')\n",
    "\n",
    "\n",
    "LL_MR_data = {}\n",
    "for kt in thread_list:\n",
    "    LL_MR_data[kt] = thread_LLM_data[kt] / thread_LLA_data[kt]\n",
    "\n",
    "def thread_bar_plots(data_dict, t_list, y=-1):\n",
    "    for kt in t_list:\n",
    "        print \"Thread Count: %d\" % kt\n",
    "        data = list(data_dict[kt])\n",
    "        matplotlib.pyplot.bar(range(len(data)), data)\n",
    "        if y != -1:\n",
    "            matplotlib.pyplot.ylim(ymax=y)\n",
    "        matplotlib.pyplot.show()\n",
    "\n",
    "thread_bar_plots(LL_MR_data, thread_list, 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L3 Top 10 bad miss rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L3_data = select_metric_from_scaling(metric_data, 'DERIVED_L3_MISSRATE')\n",
    "L3_MR_dict = {}\n",
    "for n_thr in thread_list:\n",
    "    L3_MR_dict[n_thr] = filter_libs_out(L3_data[n_thr]).sort_values(by='Inclusive',ascending=False)[[\"Inclusive\"]]\n",
    "print thread_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THREAD_COUNT = 32\n",
    "L3_MR_dict[THREAD_COUNT].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_plot_2(data, inclusive=True, plot=True, function=\"SelectHitInd\", metric='DERIVED_L3_MISSRATE', max=False):\n",
    "    '''\n",
    "    data is the whole scaling data\n",
    "    function is what to search in the call-path please use regular functions\n",
    "        default looks at the whole application\n",
    "    metric is the metric to plot\n",
    "\n",
    "    returns lists of threads and metrics per thread (i.e. data to plot)\n",
    "    '''\n",
    "    if inclusive: which='Inclusive'\n",
    "    else: which='Exclusive'\n",
    "\n",
    "    metric_data = select_metric_from_scaling(data, metric)\n",
    "    thread_list  = sorted(metric_data.keys())\n",
    "    if max:\n",
    "        data_list = [metric_data[kt][metric_data[kt].index.get_level_values('region').str.contains(function)][which].max() for kt in thread_list]\n",
    "    else:\n",
    "        # cause TAU has 2 of everything average is half\n",
    "        data_list = [metric_data[kt][metric_data[kt].index.get_level_values('region').str.contains(function)][which].sum()/(2*kt) for kt in thread_list]\n",
    "    \n",
    "    if plot: plt = matplotlib.pyplot.plot(thread_list, data_list)\n",
    "\n",
    "    return thread_list, data_list\n",
    "\n",
    "t,d = scaling_plot_2(metric_data, inclusive=True, plot=True, function=\"MultHelixPropTransp\", metric='DERIVED_L1_MISSRATE', max=False)\n",
    "print d[8]\n",
    "t,d = scaling_plot_2(metric_data, inclusive=True, plot=True, function=\"MultHelixPropTransp\", metric='DERIVED_L1_MISSRATE', max=True)\n",
    "print d[8]\n",
    "\n",
    "# 0.0002159764720002364\n",
    "# 0.024189364864026477"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Resource Stalls vs thread count\n",
    "Similar to above these cells show the Resource Stalls. In this case we have nothing to compute, so we simply call the function. Future work includes exploring the different types of stalls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_list, res_stall_data = scaling_plot(metric_data, metric='PAPI_RES_STL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_stall_data = get_thread_level_metric_scaling(metric_data, metric='PAPI_RES_STL')\n",
    "thread_bar_plots(thread_stall_data, thread_list, 4000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = combine_metrics(metric_data[32],'Inclusive')\n",
    "cm = sns.light_palette(\"yellow\", as_cmap=True)\n",
    "correlations_pearson = alldata.corr('pearson').fillna(0)    # Other methods: 'kendall', 'spearman'\n",
    "correlations_pearson.style.format(\"{:.2%}\").background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
